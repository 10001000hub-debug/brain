OpenCrowの設計図をここに書きたい。
いつかはローカルLLMをサブエージェントとして登録してやり直します。

今日はスクリプトを組んで、OpenCrowがOllamaに対してタスクを投げ、それに応答するという形で終結します。
docker exec -it ollama ollama run llama3このコマンドを打ってから、UbuntuのOllamaと会話することが可能です。